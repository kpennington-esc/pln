{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Traductor\n",
    "Ejemplo basado en [LINK](https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen del ejercicio:\n",
    "Se realizaron cambios menores para que la notebook de pytorch al menos\n",
    "pudiera completar la ejecucion.\n",
    "\n",
    "El mas relevante fue enviar los inputs de la funcion `summary` al mismo `device`\n",
    "```\n",
    "encoder_input_data, decoder_input_data, decoder_output_data = data_set[0:1]\n",
    "summary(model, input_data=(encoder_input_data.to(device), decoder_input_data.to(device)))\n",
    "```\n",
    "ademas fue necesario modificar la sintaxis para llamar al siguiente elemento de un iterador.\n",
    "\n",
    "Por otro lado, para que la notebook pudiera correr en colab, fue necesario downgradear la version de `numpy` a una menor que 2.0.\n",
    "\n",
    "Una vez solucionados los inconvenientes basicos, la notebook corre de principio a fin.\n",
    "\n",
    "### DATASET REDUCIDO\n",
    "Como se destacaba en el ejemplo, el modelo debia ser entrenado con dataset y embeddings reducidos por el acelerado incremento en el uso de RAM que impediria la ejecucion de la notebook.\n",
    "\n",
    "Corriendo con los valores por defecto (un subconjunto de 6000 lineas del dataset -cantidad de frases-, vocabulario limitado a aproximadamente 8000, y longitudes de sentencia 16 y 18) el modelo lograba aprender y desempeñar bien en test y validacion, con puntajes de accuracy superiores a 0.7.\n",
    "\n",
    "El problema con esto es que el conjunto reducido del set de entrenamiento tornaba inservible el modelo al momento de traducir. Un desempeño pauperrimo.\n",
    "\n",
    "Como la accuracy del modelo al momento de entrenar se encontraba en un buen puntaje, se puede asumir que el problema no es de aprendizaje; y se podria argumentar que mejorar el modelo o lograr que la acuraccy suba a valores cercanos a 1 no iba a mejorar las traducciones generadas. Esto es asi porque el problema esta no en el aprendizaje sino en los datos empleados para el mismo.\n",
    "\n",
    "Por ello se busco poder incrementar el tamanio del set de entrenamiento.\n",
    "\n",
    "Sin embargo, con la notebook en el estado actual, la unica forma era\n",
    "*finetunear* los valores de MAX_VOCAB_SIZE, MAX_NUM_SENTENCES, max_input_len y max_out_len de manera de lograr usar toda la ram posible, sin saturar.  Pero los numeros siguen siendo bajos en este approach (NUM_SENTENCES ~ 8000, VOCAB_SIZE ~ 10, y max input y output ~20). Con estos valores el comportamiento del modelo no cambia.\n",
    "\n",
    "La accuracy sube un poco, pero al momento de generar traducciones el resultado es el mismo.\n",
    "Pero es esperable, estamos en cualquier caso usando menos del 10% del set de frases para entrenar.\n",
    "\n",
    "### PUSHING DATASET\n",
    "\n",
    "Los esfuerzos se concentraron entonces en poder correr el modelo con un mejor set de entrenamiento. Monitoreando el uso de ram en la notebook se detecto que el pico de uso se producia al hace *onehot* para el encoder/decoder\n",
    "  ```python\n",
    "  self.decoder_outputs = F.one_hot(torch.from_numpy(decoder_output).to(torch.int64), num_classes=num_words_output).float()\n",
    "  ```\n",
    "\n",
    "  Modificando esa seccion, se puede cargar todo el dataset\n",
    "```python\n",
    "  MAX_NUM_SENTENCES = 118964\n",
    "  MAX_VOCAB_SIZE = 27000\n",
    "  max_input_len = 47\n",
    "  max_out_len = 50\n",
    "```\n",
    "\n",
    "encoder_input_sequences shape: (118964, 47)\n",
    "decoder_input_sequences shape: (118964, 50)\n",
    "\n",
    "pero sin el one-hot, al cargar el dataset solo se usan 4gb de ram y la notebook se puede correr.\n",
    "\n",
    "Evidentemente esto trae un nuevo problema que es que el tiempo de entrenamiento se dispara, se intento correr 1 epoch y el entrenamiento demoró mas de 1.30h\n",
    "\n",
    "Por tal motivo se compatibilizo la notebook con colab, y se hicieron los cambios necesarios para correr en gpu y asi acelerar el entrenamiento ...\n",
    "\n",
    "Como incluso usando GPU el tiempo de entrenamiento resultaba prohibitivo, se busco acelerar un poco el tiempo requerido.\n",
    "\n",
    "Se modifico el paso forward del s2s vectorizando los decoders para no depender de un loop de python\n",
    "\n",
    "se modifico esto:\n",
    "```python\n",
    "        for t in range(decoder_input_len):\n",
    "            # t --> token index\n",
    "\n",
    "            # utilizamos método \"teacher forcing\", es decir que durante\n",
    "            # el entrenamiento no realimentamos la salida del decoder\n",
    "            # sino el token correcto que sigue en target\n",
    "            input = decoder_input[:, t:t+1]\n",
    "\n",
    "            # ingresar cada token embedding, uno por uno junto al hidden state\n",
    "            # recibir el output del decoder (softmax)\n",
    "            output, prev_state = self.decoder(input, prev_state)\n",
    "            top1 = output.argmax(1).view(-1, 1)\n",
    "\n",
    "            # Sino se usará \"teacher forcing\" habría que descomentar\n",
    "            # esta linea.\n",
    "            # Hay ejemplos dandos vuelta en donde se utilza un random\n",
    "            # para ver en cada vuelta que técnica se aplica\n",
    "            #input = top1            \n",
    "\n",
    "            # guardar cada salida (softmax)\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "        return outputs\n",
    "```\n",
    "```python\n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        prev_state = self.encoder(encoder_input)\n",
    "        decoder_output, _ = self.decoder.lstm(self.decoder.embedding(decoder_input), prev_state)\n",
    "        out = self.decoder.fc1(decoder_output)\n",
    "        return out\n",
    "```\n",
    "\n",
    "no estoy seguro de si esto rompe la consigna, pero de otra forma no pude\n",
    "entrenar con todo el dataset.\n",
    "\n",
    "De esta forma se redujo notablemente el tiempo de entrenamiento, en colab GPU, 10 epochs en unos minutos. En CPU unos 10 minutos por ecpoh, manejable.\n",
    "\n",
    "## Resultados\n",
    "\n",
    "Al final de la notebook se pueden ver las traducciones realizadas con todo el dataset. Si bien no se dispone de una medida rigurosa,\n",
    "podria decirse que el traductor \"mejoro\" (con algo de generosidad).\n",
    "Sin embargo, sigue fallando en tareas sencillas.\n",
    "\n",
    "Ejemplos:\n",
    "-\n",
    "========================================\n",
    "\n",
    "Input: You can never be too careful.\n",
    "\n",
    "Response: no puedes ser más cuidadoso\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: Don't pretend what you don't feel.\n",
    "\n",
    "Response: no te preocupes por lo que quieras\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: They mean well.\n",
    "\n",
    "Response: tom se ve bien\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: Tom was here all day.\n",
    "\n",
    "Response: tom estaba teniendo un día\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: We are dreaming of a better future.\n",
    "\n",
    "Response: nos estamos quedando dormidos en una granja\n",
    "\n",
    "========================================\n",
    "\n",
    "Algo que se nota es que Tom esta sobrerepresentado en las traducciones\n",
    "\n",
    "## Otras frases\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: the cat is under the table\n",
    "\n",
    "Response: el gato está en la mesa\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: the bus is blue\n",
    "\n",
    "Response: el libro es azul\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: the car is under the table\n",
    "\n",
    "Response: el gato está en la mesa\n",
    "\n",
    "========================================\n",
    "\n",
    "Input: big house\n",
    "\n",
    "Response: traed ayuda\n",
    "\n",
    "========================================\n",
    "\n",
    "Puede verse un patron en como se equivoca... mira la primer letra de las palabras (seran palabras que no conoce?)\n",
    "por ejemplo  Bus > Book\n",
    "en \"the car\".. confunde con \"the Cat\"\n",
    "\n",
    "\"big house\" > \"Bring Help\" > \"traed ayuda\" (??) podria ser\n",
    "\n",
    "Pregunta, que pasa si le pasamos letras solas??\n",
    "\n",
    "Input: A | Response: ¡atacad\n",
    "\n",
    "Input: B | Response: ¡corre\n",
    "\n",
    "Input: C | Response: ¡felicidades\n",
    "\n",
    "Input: D | Response: ¡eso\n",
    "\n",
    "Input: F | Response: ¡disparad\n",
    "\n",
    "Input: G | Response: vete\n",
    "\n",
    "Input: H | Response: besado\n",
    "\n",
    "Input: I | Response: está fuera\n",
    "\n",
    "Input: J | Response: ¡salta\n",
    "\n",
    "Input: K | Response: besado\n",
    "\n",
    "Input: L | Response: escuchen\n",
    "\n",
    "Input: M | Response: tom\n",
    "\n",
    "Input: N | Response: ahora\n",
    "\n",
    "Input: O | Response: ¡órale\n",
    "\n",
    "Input: P | Response: continúa\n",
    "\n",
    "Input: Q | Response: besado\n",
    "\n",
    "Input: R | Response: ¡corre\n",
    "\n",
    "Input: S | Response: ¡parad\n",
    "\n",
    "Input: T | Response: ¡genial\n",
    "\n",
    "En la mayoria se ve este patron, mira esa letra y extrapola: A > Attack, C > Congratulations, F > Fire!, G > Go, J > Jump, L > listen\n",
    "(igual para Now, Stop, Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FGmtK8J19PNk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchinfo in /home/kpennington/.local/lib/python3.10/site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --no-cache-dir gdown --quiet\n",
    "%pip install torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1655153151153,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "vgYatMIdk_eT",
    "outputId": "0e10c3c2-721c-48d7-9f13-ca80f175b9e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2480,
     "status": "ok",
     "timestamp": 1655153153629,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "OYpIWGaXxfKe",
    "outputId": "0fa2ee70-0efc-42de-f656-2fff41c2d0f8"
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GHFPS5KNxgR9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "if os.access('torch_helpers.py', os.F_OK) is False:\n",
    "    if platform.system() == 'Windows':\n",
    "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
    "    else:\n",
    "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tP-fbmHUgbtp"
   },
   "outputs": [],
   "source": [
    "def sequence_acc(output, target):\n",
    "    predictions = output.argmax(dim=-1) \n",
    "    \n",
    "    correct = (predictions == target).float()\n",
    "\n",
    "    \n",
    "    accuracy = correct.mean()\n",
    "    return accuracy\n",
    "\n",
    "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
    "    # Defino listas para realizar graficas de los resultados\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    valid_loss = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_encoder_input, train_decoder_input, train_target in train_loader:\n",
    "            \n",
    "            train_encoder_input = train_encoder_input.to(device)\n",
    "            train_decoder_input = train_decoder_input.to(device)\n",
    "            train_target = train_target.to(device)\n",
    "\n",
    "            # Seteo los gradientes en cero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(train_encoder_input, train_decoder_input)\n",
    "\n",
    "            loss = criterion(output.reshape(-1, output.shape[-1]), \n",
    "                           train_target.reshape(-1))\n",
    "            \n",
    "            # Almaceno el error del batch\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculo el accuracy del batch\n",
    "            accuracy = sequence_acc(output, train_target)\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)        \n",
    "        train_accuracy.append(epoch_train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_encoder_input, valid_decoder_input, valid_target = next(iter(valid_loader))\n",
    "            valid_encoder_input = valid_encoder_input.to(device)\n",
    "            valid_decoder_input = valid_decoder_input.to(device)\n",
    "            valid_target = valid_target.to(device)\n",
    "            \n",
    "            output = model(valid_encoder_input, valid_decoder_input)\n",
    "            \n",
    "            # NEW: Efficient validation loss\n",
    "            epoch_valid_loss = criterion(output.reshape(-1, output.shape[-1]), \n",
    "                                       valid_target.reshape(-1))\n",
    "            epoch_valid_loss = epoch_valid_loss.item()\n",
    "            valid_loss.append(epoch_valid_loss)\n",
    "\n",
    "            # Calculo el accuracy de la epoch\n",
    "            epoch_valid_accuracy = sequence_acc(output, valid_target).item()\n",
    "            valid_accuracy.append(epoch_valid_accuracy)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n",
    "\n",
    "    history = {\n",
    "        \"loss\": train_loss,\n",
    "        \"accuracy\": train_accuracy,\n",
    "        \"val_loss\": valid_loss,\n",
    "        \"val_accuracy\": valid_accuracy,\n",
    "    }\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BFiCH8nxoIY"
   },
   "source": [
    "### 1 - Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1655153154044,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "RHNkUaPp6aYq",
    "outputId": "3117e225-7ca5-4b41-9268-2278a1686533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset ya se encuentra descargado\n"
     ]
    }
   ],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "import os\n",
    "import gdown\n",
    "if os.access('spa-eng', os.F_OK) is False:\n",
    "    if os.access('simpsons_dataset.zip', os.F_OK) is False:\n",
    "        url = 'http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n",
    "        output = 'spa-eng.zip'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "    !unzip -q spa-eng.zip   \n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1655153154355,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "-9aNLZBDtA5J",
    "outputId": "68de3ded-aa96-40fe-fab5-8083525e8c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows disponibles: 118964\n",
      "Cantidad de rows utilizadas: 118964\n"
     ]
    }
   ],
   "source": [
    "# dataset_file\n",
    "\n",
    "text_file = \"./spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Por limitaciones de RAM no se leen todas las filas\n",
    "MAX_NUM_SENTENCES = 118964\n",
    "\n",
    "# Mezclar el dataset, forzar semilla siempre igual\n",
    "np.random.seed([40])\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "count = 0\n",
    "\n",
    "for line in lines:\n",
    "    count += 1\n",
    "    if count > MAX_NUM_SENTENCES:\n",
    "        break\n",
    "\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    # Input sentence --> eng\n",
    "    # output --> spa\n",
    "    input_sentence, output = line.rstrip().split('\\t')\n",
    "\n",
    "    # output sentence (decoder_output) tiene <eos>\n",
    "    output_sentence = output + ' <eos>'\n",
    "    # output sentence input (decoder_input) tiene <sos>\n",
    "    output_sentence_input = '<sos> ' + output\n",
    "\n",
    "    input_sentences.append(input_sentence)\n",
    "    output_sentences.append(output_sentence)\n",
    "    output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows disponibles:\", len(lines))\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1655153154355,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "93IGMKFb73q7",
    "outputId": "a86baec0-a710-4da5-e2fd-478c60c769bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A deal is a deal.',\n",
       " 'Un trato es un trato. <eos>',\n",
       " '<sos> Un trato es un trato.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[0], output_sentences[0], output_sentences_inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5WAZGOTfGyha"
   },
   "outputs": [],
   "source": [
    "# Definir el tamaño máximo del vocabulario\n",
    "MAX_VOCAB_SIZE = 27000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655153154356,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "eF1W6peoFGXA",
    "outputId": "e748ad10-0c8d-4bca-ab4c-76f1974e12cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 13524\n",
      "Sentencia de entrada más larga: 47\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar las palabras con el Tokenizer de Keras\n",
    "# Definir una máxima cantidad de palabras a utilizar:\n",
    "# - num_words --> the maximum number of words to keep, based on word frequency.\n",
    "# - Only the most common num_words-1 words will be kept.\n",
    "from torch_helpers import Tokenizer\n",
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1655153154936,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "zBzdKiTVIBYY",
    "outputId": "f313cf87-642e-4671-b88d-90ecd0e80c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 26341\n",
      "Sentencia de salida más larga: 50\n"
     ]
    }
   ],
   "source": [
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26342"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(word2idx_outputs))\n",
    "num_words_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqb8ZJ4sJHgv"
   },
   "source": [
    "Como era de esperarse, las sentencias en castellano son más largas que en inglés, y lo mismo sucede con su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pgLC706EQx3p"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de que no explote la RAM se limitará el tamaño de las sentencias de entrada\n",
    "# a la mitad:\n",
    "max_input_len = 47\n",
    "max_out_len = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGOn9N57IuYz"
   },
   "source": [
    "A la hora de realiza padding es importante teneer en cuenta que en el encoder los ceros se agregan al comienoz y en el decoder al final. Esto es porque la salida del encoder está basado en las últimas palabras de la sentencia (son las más importantes), mientras que en el decoder está basado en el comienzo de la secuencia de salida ya que es la realimentación del sistema y termina con fin de sentencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1655153154937,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "q0Ob4hAWJkcv",
    "outputId": "9152d151-b863-49c9-e527-940d37a85385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "Cantidad de rows del dataset: 118964\n",
      "encoder_input_sequences shape: (118964, 47)\n",
      "decoder_input_sequences shape: (118964, 50)\n"
     ]
    }
   ],
   "source": [
    "from torch_helpers import pad_sequences\n",
    "print(np.version.full_version)\n",
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1655153154937,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "3VySR1pzx9UG",
    "outputId": "3dfeac8e-beed-4069-ffe9-1420bd7bfaa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output_sequences shape: (118964, 50)\n"
     ]
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK4blEEsRQv3"
   },
   "source": [
    "La última capa del modelo (softmax) necesita que los valores de salida\n",
    "del decoder (decoder_sequences) estén en formato oneHotEncoder.\\\n",
    "Se utiliza \"decoder_output_sequences\" con la misma estrategía que se transformó la entrada del decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1655153154938,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "ANTOqJ0WWw-q",
    "outputId": "eba76a92-1e3c-4380-8e60-761ee7e43746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118964, 50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(decoder_output_sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4345,
     "status": "ok",
     "timestamp": 1655153159276,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "SD0bpM32yWfB",
    "outputId": "f7b48899-43d3-4b7b-fd59-0bdbae7bc2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_size: 47\n",
      "decoder_input_size: 50\n"
     ]
    }
   ],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
    "        # Convertir los arrays de numpy a tensores\n",
    "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n",
    "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n",
    "        # Store as integer tensors with dtype int64 (long)\n",
    "        self.decoder_outputs = torch.from_numpy(decoder_output.astype(np.int64))  # Change to int64\n",
    "        self.len = self.decoder_outputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
    "\n",
    "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
    "print(\"encoder_input_size:\", encoder_input_size)\n",
    "\n",
    "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
    "print(\"decoder_input_size:\", decoder_input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1655153159536,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "sUDPZeuAU1RI",
    "outputId": "f19e0632-7cfd-4671-dddc-edbcf715788f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 95172\n",
      "Tamaño del conjunto de validacion: 23792\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "valid_set_size = int(data_set.len * 0.2)\n",
    "train_set_size = data_set.len - valid_set_size\n",
    "\n",
    "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
    "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
    "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1655153159537,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "9OcT-DLzkHS8",
    "outputId": "ffac352c-8ad7-4906-a86a-921999921442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los embeddings gloveembedding.pkl ya están descargados\n"
     ]
    }
   ],
   "source": [
    "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
    "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
    "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
    "import os\n",
    "import gdown\n",
    "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
    "    output = 'gloveembedding.pkl'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZgqtV8GpkSc8"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Mosj2-x-kXBK"
   },
   "outputs": [],
   "source": [
    "# Por una cuestion de RAM se utilizará los embeddings de Glove de dimension 50\n",
    "model_embeddings = GloveEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1655153166401,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "b9FS8ca1ke_B",
    "outputId": "b5ef8b04-2fff-489e-e786-1472d2c41fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 218\n"
     ]
    }
   ],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en ingles\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1655153166402,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "4q3U_WmEYRdH",
    "outputId": "e47190cf-275f-49c8-b63f-ed1aa245872a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13524"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1655153166402,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "FpzJODHBlAtE",
    "outputId": "d879d7dc-81a3-4cdc-bf1f-f5ba51aeea80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13524, 50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión de los embeddings de la secuencia en ingles\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14732,
     "status": "ok",
     "timestamp": 1655153181107,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "3fm3HCLMPSG-",
    "outputId": "39be3183-0a69-49a5-8aa1-9f24026edf32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Seq2Seq                                  [1, 50, 26342]            --\n",
       "├─Encoder: 1-1                           [1, 1, 128]               --\n",
       "│    └─Embedding: 2-1                    [1, 47, 50]               (676,200)\n",
       "│    └─LSTM: 2-2                         [1, 47, 128]              92,160\n",
       "├─Decoder: 1-2                           --                        --\n",
       "│    └─Embedding: 2-3                    [1, 50, 50]               1,317,100\n",
       "│    └─LSTM: 2-4                         [1, 50, 128]              92,160\n",
       "│    └─Linear: 2-5                       [1, 50, 26342]            3,398,118\n",
       "==========================================================================================\n",
       "Total params: 5,575,738\n",
       "Trainable params: 4,899,538\n",
       "Non-trainable params: 676,200\n",
       "Total mult-adds (M): 14.33\n",
       "==========================================================================================\n",
       "Input size (MB): 46.16\n",
       "Forward/backward pass size (MB): 10.67\n",
       "Params size (MB): 22.30\n",
       "Estimated Total Size (MB): 79.14\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
    "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
    "        self.lstm_size = 128\n",
    "        self.num_layers = 1\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
    "                            num_layers=self.num_layers) # LSTM layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        lstm_output, (ht, ct) = self.lstm(out)\n",
    "        return (ht, ct)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, output_dim):\n",
    "        super().__init__()\n",
    "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
    "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
    "        self.lstm_size = 128\n",
    "        self.num_layers = 1\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
    "                            num_layers=self.num_layers) # LSTM layer\n",
    "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim) # Fully connected layer\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        out = self.embedding(x)\n",
    "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
    "        out = self.fc1(lstm_output[:, -1, :]) \n",
    "        return out, (ht, ct)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        assert encoder.lstm_size == decoder.lstm_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.num_layers == decoder.num_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "        \n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        prev_state = self.encoder(encoder_input)\n",
    "        decoder_output, _ = self.decoder.lstm(self.decoder.embedding(decoder_input), prev_state)\n",
    "        out = self.decoder.fc1(decoder_output)\n",
    "        return out \n",
    "\n",
    "encoder = Encoder(vocab_size=nb_words)\n",
    "if cuda: encoder.cuda()\n",
    "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
    "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
    "if cuda: decoder.cuda()\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "if cuda: model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "if cuda:\n",
    "    criterion = criterion.to(device)\n",
    "encoder_input_data, decoder_input_data, decoder_output_data = data_set[0:1]\n",
    "summary(model, input_data=(encoder_input_data.to(device), decoder_input_data.to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 597334,
     "status": "ok",
     "timestamp": 1655153778405,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "VDB0KWIegt8s",
    "outputId": "d1e002a8-fa8e-4dfc-f144-a95732026f94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 - Train loss 0.832 - Train accuracy 0.885 - Valid Loss 0.642 - Valid accuracy 0.899\n",
      "Epoch: 2/10 - Train loss 0.601 - Train accuracy 0.901 - Valid Loss 0.569 - Valid accuracy 0.904\n",
      "Epoch: 3/10 - Train loss 0.531 - Train accuracy 0.907 - Valid Loss 0.534 - Valid accuracy 0.908\n",
      "Epoch: 4/10 - Train loss 0.485 - Train accuracy 0.911 - Valid Loss 0.512 - Valid accuracy 0.911\n",
      "Epoch: 5/10 - Train loss 0.449 - Train accuracy 0.913 - Valid Loss 0.503 - Valid accuracy 0.914\n",
      "Epoch: 6/10 - Train loss 0.421 - Train accuracy 0.916 - Valid Loss 0.487 - Valid accuracy 0.915\n",
      "Epoch: 7/10 - Train loss 0.398 - Train accuracy 0.918 - Valid Loss 0.487 - Valid accuracy 0.916\n",
      "Epoch: 8/10 - Train loss 0.379 - Train accuracy 0.921 - Valid Loss 0.481 - Valid accuracy 0.917\n",
      "Epoch: 9/10 - Train loss 0.363 - Train accuracy 0.923 - Valid Loss 0.473 - Valid accuracy 0.916\n",
      "Epoch: 10/10 - Train loss 0.349 - Train accuracy 0.925 - Valid Loss 0.481 - Valid accuracy 0.915\n"
     ]
    }
   ],
   "source": [
    "history1 = train(model,\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                epochs=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1655154657801,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "pZzm3tx059Zv",
    "outputId": "b7a08ad6-392e-4e40-8491-fb707d23254c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=history1['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "71XeCtfYmOFx"
   },
   "outputs": [],
   "source": [
    "# Armar lo conversores de indice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: My friend is in jail\n",
      "Representacion en vector de tokens de ids [18, 234, 7, 9, 1674]\n",
      "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    18  234    7    9 1674]]\n",
      "Index/token de salida: 21\n",
      "Palabra de salida: mi\n"
     ]
    }
   ],
   "source": [
    "input_test = \"My friend is in jail\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "\n",
    "# Se obtiene la salida del encoder (el estado oculto para el decoder)\n",
    "prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
    "\n",
    "# Se inicializa la secuencia de entrada al decoder como \"\"\n",
    "target_seq = np.zeros((1, 1))\n",
    "target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
    "\n",
    "# Se obtiene la primera palabra de la secuencia de salida del decoder\n",
    "output, prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
    "\n",
    "top1 = output.argmax(1).view(-1, 1)\n",
    "idx = int(top1.cpu())\n",
    "print(\"Index/token de salida:\", idx)\n",
    "\n",
    "word = idx2word_target[idx]\n",
    "print(\"Palabra de salida:\", word)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MlUyp9M6ua2V"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los stados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\"\n",
    "    prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
    "\n",
    "    # Se obtiene el indice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output, new_prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
    "        top1 = output.argmax(1).view(-1, 1)\n",
    "        idx = int(top1.cpu())\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar ídx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dado la ultimo prediccion\n",
    "        prev_state = new_prev_state\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
    "        target_seq_tensor = top1\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1655078833393,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "Fd6VJcZb9It_",
    "outputId": "34ba4041-04ca-4632-e69e-eaa3c9b813e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: My mother say hi.\n",
      "Representacion en vector de tokens de ids [18, 199, 126, 2318]\n",
      "Padding del vector: [[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0   18  199  126 2318]]\n",
      "Response: mi madre le hizo daño\n"
     ]
    }
   ],
   "source": [
    "input_test = \"My mother say hi.\"\n",
    "print('Input:', input_test)\n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "print(\"Padding del vector:\", encoder_sequence_test)\n",
    "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1655078869839,
     "user": {
      "displayName": "Hernán Contigiani",
      "userId": "01142101934719343059"
     },
     "user_tz": 180
    },
    "id": "ZhGVjLKcunxW",
    "outputId": "3485ea42-1dd1-4563-e655-2672203e1977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: You can never be too careful.\n",
      "Response: no puedes ser más cuidadoso\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: Don't pretend what you don't feel.\n",
      "Response: no te preocupes por lo que quieras\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: They mean well.\n",
      "Response: tom se ve bien\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: We are dreaming of a better future.\n",
      "Response: nos estamos quedando dormidos en una granja\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1]\n",
    "encoder_sequence_test_tensor = torch.from_numpy(input_seq.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test_tensor)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: the cat is under the table\n",
      "Response: el gato está en la mesa\n"
     ]
    }
   ],
   "source": [
    "input_test = \"the cat is under the table\"\n",
    "print(\"Input:\", input_test) \n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: the bus is blue\n",
      "Response: el libro es azul\n"
     ]
    }
   ],
   "source": [
    "input_test = \"the bus is blue\"\n",
    "print(\"Input:\", input_test) \n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: the car is under the table\n",
      "Response: el gato está en la mesa\n"
     ]
    }
   ],
   "source": [
    "input_test = \"the car is under the table\"\n",
    "print(\"Input:\", input_test) \n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: big house\n",
      "Response: traed ayuda\n"
     ]
    }
   ],
   "source": [
    "input_test = \"big house\"\n",
    "print(\"Input:\", input_test) \n",
    "integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "translation = translate_sentence(encoder_sequence_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: A | Response: ¡atacad\n",
      "\n",
      "Input: B | Response: ¡corre\n",
      "\n",
      "Input: C | Response: ¡felicidades\n",
      "\n",
      "Input: D | Response: ¡eso\n",
      "\n",
      "Input: F | Response: ¡disparad\n",
      "\n",
      "Input: G | Response: vete\n",
      "\n",
      "Input: H | Response: besado\n",
      "\n",
      "Input: I | Response: está fuera\n",
      "\n",
      "Input: J | Response: ¡salta\n",
      "\n",
      "Input: K | Response: besado\n",
      "\n",
      "Input: L | Response: escuchen\n",
      "\n",
      "Input: M | Response: tom\n",
      "\n",
      "Input: N | Response: ahora\n",
      "\n",
      "Input: O | Response: ¡órale\n",
      "\n",
      "Input: P | Response: continúa\n",
      "\n",
      "Input: Q | Response: besado\n",
      "\n",
      "Input: R | Response: ¡corre\n",
      "\n",
      "Input: S | Response: ¡parad\n",
      "\n",
      "Input: T | Response: ¡genial\n"
     ]
    }
   ],
   "source": [
    "for l in [\"A\", \"B\", \"C\", \"D\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\" ]:\n",
    "    \n",
    "    input_test = l\n",
    "  \n",
    "    integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "    encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "    translation = translate_sentence(encoder_sequence_test)\n",
    "    print(f\"\\nInput: {input_test} | Response: {translation}\" ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMniDMuqoKT0lLVAJWxpRSt",
   "collapsed_sections": [],
   "name": "6c - traductor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
